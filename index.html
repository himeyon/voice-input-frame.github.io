<script>
/**
 * UIはそのまま。内部は Vosk(OSS, CDN) 優先 → 失敗時 Web Speech に自動フォールバック。
 * - vosk-browser を ESM import（jsDelivr）
 * - wasm/worker の prefix を明示
 * - モデルZIPはCORS通らなければ自社CDNへ置換
 * - マイク 48k → Workletで 16k Int16 にダウンサンプルして Vosk へ
 */
(function () {

  // DOM構築後に安全に起動（<head>でもOK）
  const run = () => {
    // ====== UI生成（元のまま）======
    // #main-box-layout が無ければ自動で作る（body未生成でもdocumentElement直下にぶら下げ）
    const root =
      document.getElementById('main-box-layout') ||
      (document.body || document.documentElement)
        .appendChild(Object.assign(document.createElement('div'), { id: 'main-box-layout' }));

    root.innerHTML =
      '<div class="wrap">' +
      '  <h1>音声入力→テキスト</h1>' +
      '  <div class="panel">' +
      '    <div class="bar">' +
      '      <label class="pill">マイク <select id="mic"></select></label>' +
      '      <label class="pill">言語 ' +
      '        <select id="lang"><option value="ja-JP" selected>ja-JP</option><option value="en-US">en-US</option></select>' +
      '      </label>' +
      '      <span id="support"></span>' +
      '    </div>' +
      '    <div class="row">' +
      '      <button id="start" class="primary">録音開始</button>' +
      '      <button id="stop" disabled>停止</button>' +
      '      <button id="saveText" disabled>テキスト保存</button>' +
      '      <span id="status"></span>' +
      '    </div>' +
      '  </div>' +
      '  <div class="panel"><textarea id="transcript" class="mono" aria-live="polite" placeholder="ここに文字起こし結果が表示されます"></textarea></div>' +
      '  <div class="row footer">' +
      '    <div>Web Speech API 非対応ブラウザでは動作しません。</div>' +
      '    <div>Copyright(C) COMTURE CORPORATION. All rights reserved.</div>' +
      '  </div>' +
      '</div>';

    // --- ここから（root.innerHTML の直後に追加）---
    if (!document.getElementById('voice-demo-css')) {
      const style = document.createElement('style');
      style.id = 'voice-demo-css';
      style.textContent = `
      :root { color-scheme: light dark; }
      * { box-sizing: border-box; }
      body { margin: 0; font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, "ヒラギノ角ゴ ProN", "メイリオ", sans-serif; }
      .wrap { max-width: 960px; margin: 24px auto; padding: 0 16px; }
      .panel { background: canvas; border: 1px solid color-mix(in srgb, CanvasText 20%, Canvas 80%);
              border-radius: 12px; padding: 12px; margin: 12px 0; }
      .bar, .row { display: flex; gap: 8px; align-items: center; flex-wrap: wrap; }
      .pill { display:inline-flex; align-items:center; gap:6px; padding:4px 10px;
              border:1px solid color-mix(in srgb, CanvasText 20%, Canvas 80%);
              background: color-mix(in srgb, Canvas 85%, CanvasText 5%);
              border-radius: 9999px; font-size: 14px; }
      select, button { font: inherit; }
      button { padding: 8px 12px; border-radius: 8px; border:1px solid transparent; cursor: pointer; }
      button.primary { background: #2563eb; color: #fff; }
      button:hover:not([disabled]) { filter: brightness(1.05); }
      button[disabled] { opacity: .5; cursor: not-allowed; }
      #transcript.mono { width: 100%; height: 220px; font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, "Liberation Mono", monospace;
                        padding: 10px; border:1px solid color-mix(in srgb, CanvasText 20%, Canvas 80%);
                        border-radius: 10px; resize: vertical; background: canvas; color: canvastext; }
      .footer { font-size: 12px; color: color-mix(in srgb, CanvasText 70%, Canvas 30%);
                display:flex; justify-content: space-between; gap:8px; padding: 4px 2px; }
      `;
      document.head.appendChild(style);
    }
    // --- ここまで ---


    // ====== 要素 ======
    const micSel = document.getElementById('mic');
    const langSel = document.getElementById('lang');
    const startBtn = document.getElementById('start');
    const stopBtn = document.getElementById('stop');
    const saveBtn = document.getElementById('saveText');
    const statusEl = document.getElementById('status');
    const supportEl = document.getElementById('support');
    const transcriptEl = document.getElementById('transcript');

    // ====== 状態 ======
    let stream = null;
    let recorder = null;
    let chunks = [];
    let recognition = null;
    let finalTexts = [];
    let interimText = '';

    // ==== Vosk 関連 ====
    let VOSK_READY = false;
    let voskModel = null;
    let voskRecognizer = null;
    let ac = null, srcNode = null, workletNode = null;

    // CDN先（バージョン固定推奨）
    const VOSK_JS_CDN   = 'https://cdn.jsdelivr.net/npm/vosk-browser@0.0.26/dist/vosk.js';
    const VOSK_WASM_CDN = 'https://cdn.jsdelivr.net/npm/vosk-browser@0.0.26/dist/';
    // 日本語モデル（CORS落ちたら自社CDNに置き換え）
    const VOSK_MODEL_ZIP = 'https://alphacephei.com/vosk/models/vosk-model-small-ja-0.22.zip';

    // 事後補正
    const normalizePairs = [
      ['りんぎ','稟議'],
      ['でんぴょう','伝票'],
    ];
    function applyNormalization(s) {
      let out = s;
      for (const [from, to] of normalizePairs) {
        const re = new RegExp(from.replace(/[.*+?^${}()|[\]\\]/g, '\\$&'), 'g');
        out = out.replace(re, to);
      }
      return out;
    }

    // ====== util ======
    const setStatus = (msg) => { statusEl.textContent = msg; };
    const renderText = () => {
      const joined = finalTexts.join(' ');
      transcriptEl.value = joined + (interimText ? (' ' + interimText) : '');
      transcriptEl.scrollTop = transcriptEl.scrollHeight;
    };
    const lockDuringRecording = (on) => {
      startBtn.disabled = on;
      stopBtn.disabled = !on;
      saveBtn.disabled = false;
      micSel.disabled = on;
      langSel.disabled = on;
    };

    // ====== マイク一覧 ======
    (function initMics() {
      const fill = (defaultDeviceId) => {
        navigator.mediaDevices.enumerateDevices().then(devices => {
          const ins = devices.filter(d => d.kind === 'audioinput');
          micSel.innerHTML = ins.map((d, j) =>
            `<option value="${d.deviceId}">${d.label || 'Microphone'} (${j+1})</option>`).join('');
          micSel.value = defaultDeviceId || ins[0]?.deviceId || '';
        });
      };
      navigator.mediaDevices.getUserMedia({ audio: true })
        .then(s => {
          const track = s.getAudioTracks()[0];
          const settings = track && track.getSettings ? track.getSettings() : {};
          const defaultId = settings.deviceId || '';
          s.getTracks().forEach(t => t.stop());
          fill(defaultId);
        })
        .catch(() => fill(''));
    })();

    // ====== Vosk 読み込み＋初期化（ESM import） ======
    async function ensureVosk() {
      if (VOSK_READY) return true;
      try {
        setStatus('Vosk 読み込み中…');

        const mod  = await import(VOSK_JS_CDN);             // ESMとして読み込む
        const Vosk = mod?.Vosk || mod?.default || window.Vosk;
        if (!Vosk) throw new Error('Vosk not loaded');

        Vosk.setWasmPrefix?.(VOSK_WASM_CDN);                // wasm/worker のベースURL
        Vosk.setLogLevel?.(-1);

        voskModel = await Vosk.createModel(VOSK_MODEL_ZIP); // モデルZIP読込
        // API差分の吸収（0.0.26 では model.Recognizer あり）
        if (voskModel?.Recognizer) {
          voskRecognizer = new voskModel.Recognizer({ sampleRate: 16000 });
        } else if (typeof Vosk.Recognizer === 'function') {
          voskRecognizer = new Vosk.Recognizer({ model: voskModel, sampleRate: 16000 });
        } else if (typeof voskModel?.createRecognizer === 'function') {
          voskRecognizer = await voskModel.createRecognizer({ sampleRate: 16000 });
        } else {
          throw new Error('Recognizer constructor not found');
        }

        VOSK_READY = true;
        supportEl.textContent = 'Vosk: ready (OSS)';
        setStatus('Vosk 準備完了');
        return true;
      } catch (e) {
        console.warn('[vosk] init failed -> fallback Web Speech', e);
        supportEl.textContent = 'SpeechRecognition: available (fallback)';
        setStatus('Vosk使えないためWeb Speechに切替');
        return false;
      }
    }

    // ====== 48kHz → 16kHz (AudioWorklet) ======
    const WORKLET_CODE = `
      class DownsamplerProcessor extends AudioWorkletProcessor {
        process(inputs) {
          const input = inputs[0];
          if (!input || input.length === 0) return true;
          const ch = input[0];
          if (!ch) return true;
          const out = new Int16Array(Math.floor(ch.length/3));
          let oi=0;
          for (let i=0;i+2<ch.length;i+=3) {
            let v = ch[i+1];
            v = Math.max(-1, Math.min(1, v));
            out[oi++] = v<0 ? v*32768 : v*32767;
          }
          this.port.postMessage(out);
          return true;
        }
      }
      registerProcessor('downsampler', DownsamplerProcessor);
    `;

    async function setupAudioGraph(stream) {
      const AC = window.AudioContext || window.webkitAudioContext;
      ac = new AC({ sampleRate: 48000 });
      srcNode = ac.createMediaStreamSource(stream);
      const blob = new Blob([WORKLET_CODE], { type: 'application/javascript' });
      const url  = URL.createObjectURL(blob);
      await ac.audioWorklet.addModule(url);
      URL.revokeObjectURL(url);
      workletNode = new AudioWorkletNode(ac, 'downsampler');
      srcNode.connect(workletNode);
      workletNode.port.onmessage = (e) => {
        if (!VOSK_READY || !voskRecognizer) return;
        const pcm16 = e.data;
        try {
          const ok = voskRecognizer.acceptWaveform(pcm16);
          if (ok) {
            const res = voskRecognizer.result();
            const txt = (res && res.text) ? res.text.trim() : '';
            if (txt) {
              const fixed = applyNormalization(txt);
              finalTexts.push(fixed.endsWith('。') ? fixed : (fixed + '。'));
              interimText = '';
              renderText();
            }
          } else {
            const pr = voskRecognizer.partialResult();
            interimText = (pr && pr.partial) ? pr.partial : '';
            renderText();
          }
        } catch (err) {
          console.warn('[vosk] accept error', err);
        }
      };
      await ac.resume(); // ユーザー操作後でも必ず呼ぶ
    }

    // ====== Web Speech ======
    const SR  = window.SpeechRecognition || window.webkitSpeechRecognition;

    // ====== クリックで全文コピー ======
    transcriptEl.addEventListener('pointerdown', async () => {
      const text = transcriptEl.value || '';
      if (!text.trim()) return;
      transcriptEl.select();
      try {
        await navigator.clipboard.writeText(text);
        setStatus('全文をクリップボードにコピーしました。');
      } catch { setStatus('全文選択のみ完了（クリップボード不可）'); }
    });

    // ====== 録音開始 ======
    startBtn.addEventListener('click', async () => {
      const deviceId = micSel.value || undefined;
      const audioConstraints = deviceId ? { deviceId } : {};
      Object.assign(audioConstraints, {
        noiseSuppression: true,
        echoCancellation: true,
        autoGainControl: true,
        channelCount: { ideal: 1 },
        sampleRate: 48000
      });

      navigator.mediaDevices.getUserMedia({ audio: audioConstraints })
        .then(async (s) => {
          stream = s;

          // 録音保存は元コードのまま
          const mime = MediaRecorder.isTypeSupported('audio/webm;codecs=opus') ? 'audio/webm;codecs=opus' : 'audio/webm';
          recorder = new MediaRecorder(stream, { mimeType: mime });
          chunks = [];
          recorder.addEventListener('dataavailable', (e) => { if (e.data && e.data.size) chunks.push(e.data); });
          recorder.start();

          finalTexts = [];
          interimText = '';

          // まずVoskを試す
          const useVosk = await ensureVosk();
          if (useVosk) {
            await setupAudioGraph(stream);
            setStatus('録音中（Vosk, ブラウザ内認識）…');
            lockDuringRecording(true);
            return;
          }

          // Fallback: Web Speech
          if (SR) {
            recognition = new SR();
            recognition.lang = langSel.value;
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.maxAlternatives = 1;

            recognition.onresult = (ev) => {
              interimText = '';
              for (let i = ev.resultIndex; i < ev.results.length; i++) {
                const r = ev.results[i];
                if (r.isFinal) finalTexts.push(applyNormalization(r[0].transcript.trim()));
                else interimText += r[0].transcript;
              }
              renderText();
            };
            recognition.onerror = (e) => {
              const err = (e && (e.error||e.name||e.message)) || 'unknown';
              if (err !== 'aborted') console.warn('[sr:error]', err);
            };
            recognition.onend = () => {
              // 勝手に止まったら自動再開
              try { recognition.start(); } catch(_) {}
            };
            try { recognition.start(); } catch (e) {}
            supportEl.textContent = 'SpeechRecognition: fallback';
          }

          lockDuringRecording(true);
          setStatus('録音中…');
        })
        .catch((err) => {
          console.error(err);
          alert('マイクの使用を許可してください。');
        });
    });

    // ====== 録音停止 ======
    stopBtn.addEventListener('click', () => {
      try { if (workletNode) workletNode.port.onmessage = null; } catch(_){}
      try { if (srcNode) srcNode.disconnect(); } catch(_){}
      try { if (workletNode) workletNode.disconnect(); } catch(_){}
      try { if (ac && ac.state !== 'closed' && ac.close) ac.close(); } catch(_){}
      workletNode = null; srcNode = null; ac = null;

      if (recognition) { try { recognition.onend = null; recognition.stop(); } catch (e) {} recognition = null; }

      new Promise((resolve) => {
        if (!recorder) { resolve(new Blob([], { type: 'audio/webm' })); return; }
        recorder.addEventListener('stop', () => {
          resolve(new Blob(chunks, { type: (recorder.mimeType || 'audio/webm') }));
        }, { once: true });
        if (recorder.state !== 'inactive') recorder.stop();
      }).then((audioBlob) => {
        if (stream) { stream.getTracks().forEach(t => t.stop()); stream = null; }
        recorder = null;

        if (interimText) {
          let txt = applyNormalization(interimText.trim());
          if (!/[。．.!?！？]$/.test(txt) && txt.length >= 4) txt += '。';
          finalTexts.push(txt);
          interimText = '';
          renderText();
        }

        setStatus('停止（音声 ' + Math.round(audioBlob.size / 1024) + ' KB）');
        lockDuringRecording(false);
      });
    });

    // ====== テキスト保存 ======
    saveBtn.addEventListener('click', () => {
      const text = transcriptEl.value || '';
      const blob = new Blob([text], { type: 'text/plain;charset=utf-8' });
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = 'transcript-' + new Date().toISOString().replace(/[:.]/g, '-') + '.txt';
      document.body.appendChild(a);
      a.click();
      a.remove();
      URL.revokeObjectURL(url);
    });

  }; // run()

  if (document.readyState === 'loading') {
    document.addEventListener('DOMContentLoaded', run, { once: true });
  } else {
    run();
  }

})();
</script>
